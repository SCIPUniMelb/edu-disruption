html_text() %>%
# remove empty white space
str_trim() %>%
# remove new line indicator \n
str_remove_all(pattern = "\n") %>%
# remove html tags
cleanFun() %>%
as_tibble()
# Clean up the text from each blog post.
p <- march_paras %>%
# remove empty white space
html_text() %>%
# remove empty white space
str_trim() %>%
# remove new line indicator \n
str_remove_all(pattern = "\n") %>%
# remove html tags
cleanFun() %>%
as_tibble()
library(tidytext)
pp <- p %>%
unnest_tokens(word, value) %>%
filter(!word %in% stop_words$word ) %>%
count(word, sort = TRUE) %>%
arrange(desc(n)) %>%
DT::datatable(options = list(
searching = FALSE,
pageLength = 5,
lengthMenu = c(5, 10, 15, 20)))
positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
# https://dplyr.tidyverse.org/reference/filter-joins.html#examples
# To suppress the message about joining variables, supply `by`
# band_members %>% semi_join(band_instruments, by = "name")
# What are the most common positive words
pos <- pp %>%
dplyr::semi_join(positive, by = "word") %>%
select(Positive = word, pos_total = n) %>%
head(20)
library(tidytext)
pp <- p %>%
unnest_tokens(word, value) %>%
filter(!word %in% stop_words$word ) %>%
count(word, sort = TRUE) %>%
arrange(desc(n))
DT::datatable(pp, editable = list(target = 'row', pageLength = 5, lengthMenu = c(5, 10, 15, 20)))
library(tidytext)
pp <- p %>%
unnest_tokens(word, value) %>%
filter(!word %in% stop_words$word ) %>%
count(word, sort = TRUE) %>%
arrange(desc(n))
DT::datatable(pp, editable = list(target = 'row', pageLength=5, lengthMenu = c(5, 10, 15, 20)))
positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
# https://dplyr.tidyverse.org/reference/filter-joins.html#examples
# To suppress the message about joining variables, supply `by`
# band_members %>% semi_join(band_instruments, by = "name")
# What are the most common positive words
pos <- pp %>%
dplyr::semi_join(positive, by = "word") %>%
select(Positive = word, pos_total = n) %>%
head(20)
# What are the most common negative words
neg <- pp %>%
dplyr::semi_join(negative, by = "word") %>%
select(Negative = word, neg_total = n) %>%
head(20)
DT::datatable(bind_cols(pos, neg), editable = list(
target = 'row', disable = list(columns = c(1, 3, 4))
))
positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
# https://dplyr.tidyverse.org/reference/filter-joins.html#examples
# To suppress the message about joining variables, supply `by`
# band_members %>% semi_join(band_instruments, by = "name")
# What are the most common positive words
pos <- pp %>%
dplyr::semi_join(positive, by = "word") %>%
select(Positive = word, pos_total = n) %>%
head(20)
# What are the most common negative words
neg <- pp %>%
dplyr::semi_join(negative, by = "word") %>%
select(Negative = word, neg_total = n) %>%
head(20)
DT::datatablebind_cols(pos, neg), (editable = list(target = 'row', pageLength = 5, lengthMenu = c(5, 10, 15, 20)))
positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
# https://dplyr.tidyverse.org/reference/filter-joins.html#examples
# To suppress the message about joining variables, supply `by`
# band_members %>% semi_join(band_instruments, by = "name")
# What are the most common positive words
pos <- pp %>%
dplyr::semi_join(positive, by = "word") %>%
select(Positive = word, pos_total = n) %>%
head(20)
# What are the most common negative words
neg <- pp %>%
dplyr::semi_join(negative, by = "word") %>%
select(Negative = word, neg_total = n) %>%
head(20)
DT::datatablebind_cols(pos, neg), editable = list(target = 'row', pageLength = 5, lengthMenu = c(5, 10, 15, 20)))
positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
# https://dplyr.tidyverse.org/reference/filter-joins.html#examples
# To suppress the message about joining variables, supply `by`
# band_members %>% semi_join(band_instruments, by = "name")
# What are the most common positive words
pos <- pp %>%
dplyr::semi_join(positive, by = "word") %>%
select(Positive = word, pos_total = n) %>%
head(20)
# What are the most common negative words
neg <- pp %>%
dplyr::semi_join(negative, by = "word") %>%
select(Negative = word, neg_total = n) %>%
head(20)
DT::datatable(bind_cols(pos, neg), editable = list(target = 'row', pageLength = 5, lengthMenu = c(5, 10, 15, 20)))
library(shiny)
library(rtweet)
library(tidyverse)
library(scales)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("Twitter Data"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
sliderInput("n",
"How many trends would you like to see?",
min = 1,
max = 25,  # helps avoid API limits of 18,000/15 mins
value = 3) # default valie
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
# Define server logic required to draw a histogram
server <- function(input, output) {
trends <- get_trends("washington")
output$trends <- renderPlot({
trends[, c('trends','tweet_volume')] %>%
arrange(desc(tweet_volume)) %>%
rename(Trend = trend, Volume = tweet_volume)
# generate bins based on input$bins from ui.R
x    <- trends$Volume
bins <- seq(min(x), max(x), length.out = input$bins + 1)
# draw the plot with the specified number of bins
ggplot() +
geom_bar(mapping = aes(x = reorder(trend, -tweet_volume),
y = tweet_volume),
stat = "identity") +
scale_y_continuous(labels = comma) +
theme(axis.title.x = element_blank()) +
theme(axis.title.y = element_blank()) +
labs(title = "Washington DC Twitter Trends",
caption = "\nSource: Data collected via rtweet - graphic by @mjhendrickson")
})
}
# Run the application
shinyApp(ui = ui, server = server)
# Sentiment analysis using tidytext
# https://www.edgarsdatalab.com/2017/09/04/sentiment-analysis-using-tidytext/
library(tidyverse)
library(here)
tweets-rl <- read_csv(here::here("Data", "tweets-remotelearning.csv"))
# Sentiment analysis using tidytext
# https://www.edgarsdatalab.com/2017/09/04/sentiment-analysis-using-tidytext/
library(tidyverse)
library(here)
tweets_rl <- read_csv(here::here("Data", "tweets-remotelearning.csv"))
View(tweets_rl)
tidy_tweets <- tibble(tweets_rl)
tweets_rl <- tibble(read_csv(here::here("Data", "tweets-remotelearning.csv")))
View(tweets_rl)
tweets_rl
library(tidytext)
tweet_words <- tweets_rl %>%
select(tweetid, screen_name, text, created_date) %>%
unnest_tokens(word, text)
View(tweets_rl)
tweet_words <- tweets_rl %>%
select(statusid, screen_name, text, created_date) %>%
unnest_tokens(word, text)
tweet_words
tweet_words <- tweets_rl %>%
select(status_id, screen_name, text, created_at) %>%
unnest_tokens(word, text)
tweet_words
stop_words
my_stop_words <- tibble(
word = c(
"https",
"t.co",
"rt",
"amp",
"rstats",
"gt"
),
lexicon = "twitter"
)
View(my_stop_words)
all_stop_words <- stop_words %>%
bind_rows(my_stop_words)
suppressWarnings({
no_numbers <- tweet_words %>%
filter(is.na(as.numeric(word)))
})
no_stop_words <- no_numbers %>%
anti_join(all_stop_words, by = "word")
tibble(
total_words = nrow(tweet_words),
after_cleanup = nrow(no_stop_words)
)
top_words <- no_stop_words %>%
group_by(word) %>%
tally %>%
arrange(desc(n)) %>%
head(10)
top_words
nrc_words <- no_stop_words %>%
inner_join(get_sentiments("nrc"), by = "word")
nrc_words
nrc_words %>%
group_by(sentiment) %>%
tally %>%
arrange(desc(n))
nrc_words %>%
group_by(tweetid) %>%
tally %>%
ungroup %>%
count %>%
pull
nrc_words %>%
group_by(status_id) %>%
tally %>%
ungroup %>%
count %>%
pull
library(ggjoy)
install.packages("ggjoy")
library(ggjoy)
ggplot(nrc_words) +
geom_joy(aes(
x = created_date,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #rstats sentiment analysis",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #rstats sentiment analysis",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
library(RColorBrewer)
library(wordcloud)
set.seed(10)
joy_words <- nrc_words %>%
filter(sentiment == "joy") %>%
group_by(word) %>%
tally
joy_words %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
other_words <- nrc_words %>%
filter(sentiment == "joy") %>%
group_by(status_id) %>%
tally %>%
ungroup() %>%
inner_join(no_stop_words, by = "status_id")  %>%
anti_join(joy_words, by = "word") %>%
anti_join(top_words, by = "word") %>%
group_by(word) %>%
count
other_words %>%
with(wordcloud(word, nn, max.words = 30, colors =  c( "#56B4E9", "#E69F00")))
other_words %>%
with(wordcloud(word, max.words = 30, colors =  c( "#56B4E9", "#E69F00")))
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #rstats sentiment analysis",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
# bing lexicon
bing_words <- no_stop_words %>%
inner_join(get_sentiments("bing"), by = "word")
bing_words
bing_words %>%
group_by(sentiment) %>%
tally %>%
arrange(desc(n))
bing_words %>%
group_by(status_id) %>%
tally %>%
ungroup %>%
count %>%
pull
# with bing lexicon
ggplot(bing_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #remotelearning sentiment analysis",
subtitle = "nrc lexicon",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
# with bing lexicon
ggplot(bing_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / bing lexicon",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
# with bing lexicon
ggplot(bing_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() with bing lexicon",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
# with nrc lexicon
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / NRC lexicon",
x = "Tweet Date",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
# with nrc lexicon
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "Twitter #remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / NRC lexicon",
x = "Date of tweet",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
ggsave(here("remotelearning_nrc_lexicon.png"),
dpi = 300,  width = 11, height = 8)
ggsave(here("remotelearning_bing_lexicon.png"),
dpi = 300,  width = 11, height = 8)
joy_words %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
# with nrc lexicon
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "#remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / NRC lexicon",
x = "Date of tweet",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
other_words %>%
with(wordcloud(word, n, max.words = 30, colors =  c( "#56B4E9", "#E69F00")))
positive_words <- nrc_words %>%
filter(sentiment == "positive") %>%
group_by(word) %>%
tally
positive_words %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
# with bing lexicon
ggplot(bing_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "#remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / bing lexicon",
x = "Date of tweet",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
positive_words_bing <- bing_words %>%
filter(sentiment == "positive") %>%
group_by(word) %>%
tally
positive_words_bing %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
negative_words_bing <- bing_words %>%
filter(sentiment == "negative") %>%
group_by(word) %>%
tally
negative_words_bing %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
# with nrc lexicon
ggplot(nrc_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "#remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / NRC lexicon",
x = "Date of tweet",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
ggsave(here("remotelearning_nrc_lexicon.png"),
dpi = 300,  width = 11, height = 8)
# with bing lexicon
ggplot(bing_words) +
geom_joy(aes(
x = created_at,
y = sentiment,
fill = sentiment),
rel_min_height = 0.01,
alpha = 0.7,
scale = 3) +
theme_joy() +
labs(title = "#remotelearning sentiment analysis",
subtitle = "tidytext / get_sentiments() / bing lexicon",
x = "Date of tweet",
y = "Sentiment") +
scale_fill_discrete(guide=FALSE)
ggsave(here("remotelearning_bing_lexicon.png"),
dpi = 300,  width = 11, height = 8)
positive_words_nrc %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
positive_words_nrc <- nrc_words %>%
filter(sentiment == "positive") %>%
group_by(word) %>%
tally
positive_words_nrc %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
positive_words_bing <- bing_words %>%
filter(sentiment == "positive") %>%
group_by(word) %>%
tally
positive_words_bing %>%
with(wordcloud(word, n, max.words = 50, colors =  c("#56B4E9", "#E69F00")))
