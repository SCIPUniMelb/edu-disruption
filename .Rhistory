to_word <- to_word %>%
select(-n) %>%
set_names(c("to", "y_to", "x_to"))
links <- crossing(from = from_word$from,
to = to_word$to) %>%
mutate(word_pair = paste(from, to),
number = map_dbl(word_pair,
~ sum(str_detect(trigram$trigram, .x)))) %>%
left_join(from_word, by = "from") %>%
left_join(to_word, by = "to")
links %>%
by_row(~ sigmoid(x_from = .x$x_from + 0.2 + x_space,
x_to = .x$x_to - 0.05,
y_from = .x$y_from, y_to = .x$y_to,
scale = scale, n = n) %>%
mutate(word_pair = .x$word_pair,
number = .x$number,
from = .x$from)) %>%
pull(.out) %>%
bind_rows()
}
egde_lines(trigram = trigrams,
from_word = filter(nodes, x == 1),
to_word = filter(nodes, x == 2)) %>%
filter(number > 0) %>%
ggplot(aes(x, y, group = word_pair, alpha = number, color = from)) +
geom_line()
# egdes between first and second column
egde1 <- egde_lines(trigram = trigrams,
from_word = filter(nodes, x == 1),
to_word = filter(nodes, x == 2),
n = 50) %>%
filter(number > 0) %>%
mutate(id = word_pair)
# Words in second colunm
## That start with he
second_word_he <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
second_word_she <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# Words in third colunm
## That start with he
third_word_he <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
third_word_she <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# egdes between second and third column that starts with he
egde2_he <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[1], " "))),
second_word_he, third_word_he, n = 50) %>%
mutate(y = y + 0.05,
from = start_words[1],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# egdes between second and third column that starts with she
egde2_she <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[2], " "))),
second_word_she, third_word_she, n = 50) %>%
mutate(y = y - 0.05,
from = start_words[2],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# All edges
edges <- bind_rows(egde1, egde2_he, egde2_she)
p <- nodes %>%
ggplot(aes(x, y, label = word, size = n)) +
geom_text(hjust = 0, color = "#DDDDDD") +
theme_void() +
geom_line(data = edges,
aes(x, y, group = id, color = from, alpha = sqrt(number)),
inherit.aes = FALSE) +
theme(plot.background = element_rect(fill = "#666666", colour = 'black'),
text = element_text(color = "#EEEEEE", size = 15)) +
guides(alpha = "none", color = "none", size = "none") +
xlim(c(0.9, 3.2)) +
scale_color_manual(values = c("#5EF1F1", "#FA62D0")) +
labs(title = " Vizualizing trigrams in Jane Austen's, Emma") +
scale_size(range = c(3, 8))
p
n_word <- 20
n_top <- 150
n_gramming <- 3
trigrams <- tibble(text = janeaustenr::emma) %>%
unnest_tokens(trigram, text, token = "ngrams", n = n_gramming)
start_words <- c("i", "you")
n_word <- 20
n_top <- 150
n_gramming <- 3
trigrams <- tibble(text = janeaustenr::emma) %>%
unnest_tokens(trigram, text, token = "ngrams", n = n_gramming)
start_words <- c("i", "you")
pattern <- str_c("^", start_words, " ", collapse = "|")
top_words <- trigrams %>%
filter(str_detect(trigram, pattern)) %>%
count(trigram, sort = TRUE) %>%
slice(seq_len(n_top)) %>%
pull(trigram)
trigrams <- trigrams %>%
filter(trigram %in% top_words)
nodes <- map_df(seq_len(n_gramming),
~ trigrams %>%
mutate(word = str_nth_word(trigram, .x)) %>%
count(word, sort = TRUE) %>%
slice(seq_len(n_word)) %>%
mutate(y = seq(from = n_word + 1, to = 0,
length.out = n() + 2)[seq_len(n()) + 1],
x = .x))
# egdes between first and second column
egde1 <- egde_lines(trigram = trigrams,
from_word = filter(nodes, x == 1),
to_word = filter(nodes, x == 2),
n = 50) %>%
filter(number > 0) %>%
mutate(id = word_pair)
# Words in second colunm
## That start with he
second_word_he <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
second_word_she <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# Words in third colunm
## That start with he
third_word_he <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
third_word_she <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# egdes between second and third column that starts with he
egde2_he <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[1], " "))),
second_word_he, third_word_he, n = 50) %>%
mutate(y = y + 0.05,
from = start_words[1],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# egdes between second and third column that starts with she
egde2_she <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[2], " "))),
second_word_she, third_word_she, n = 50) %>%
mutate(y = y - 0.05,
from = start_words[2],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# All edges
edges <- bind_rows(egde1, egde2_he, egde2_she)
p <- nodes %>%
ggplot(aes(x, y, label = word, size = n)) +
geom_text(hjust = 0, color = "#DDDDDD") +
theme_void() +
geom_line(data = edges,
aes(x, y, group = id, color = from, alpha = sqrt(number)),
inherit.aes = FALSE) +
theme(plot.background = element_rect(fill = "#666666", colour = 'black'),
text = element_text(color = "#EEEEEE", size = 15)) +
guides(alpha = "none", color = "none", size = "none") +
xlim(c(0.9, 3.2)) +
scale_color_manual(values = c("#F7E720", "#7FD24E")) +
labs(title = " Vizualizing trigrams in Jane Austen's, Emma") +
scale_size(range = c(3, 8))
p
n_word <- 20
n_top <- 150
n_gramming <- 3
library(rvest)
sherlock_holmes <- read_html("https://sherlock-holm.es/stories/plain-text/cnus.txt") %>%
html_text() %>%
str_split("\n") %>%
unlist()
trigrams <- tibble(text = sherlock_holmes) %>%
unnest_tokens(trigram, text, token = "ngrams", n = n_gramming)
start_words <- c("holmes", "watson")
n_word <- 20
n_top <- 150
n_gramming <- 3
library(rvest)
sherlock_holmes <- read_html("https://sherlock-holm.es/stories/plain-text/cnus.txt") %>%
html_text() %>%
str_split("\n") %>%
unlist()
trigrams <- tibble(text = sherlock_holmes) %>%
unnest_tokens(trigram, text, token = "ngrams", n = n_gramming)
start_words <- c("holmes", "watson")
pattern <- str_c("^", start_words, " ", collapse = "|")
top_words <- trigrams %>%
filter(str_detect(trigram, pattern)) %>%
count(trigram, sort = TRUE) %>%
slice(seq_len(n_top)) %>%
pull(trigram)
trigrams <- trigrams %>%
filter(trigram %in% top_words)
nodes <- map_df(seq_len(n_gramming),
~ trigrams %>%
mutate(word = str_nth_word(trigram, .x)) %>%
count(word, sort = TRUE) %>%
slice(seq_len(n_word)) %>%
mutate(y = seq(from = n_word + 1, to = 0,
length.out = n() + 2)[seq_len(n()) + 1],
x = .x))
# egdes between first and second column
egde1 <- egde_lines(trigram = trigrams,
from_word = filter(nodes, x == 1),
to_word = filter(nodes, x == 2),
n = 50, x_space = 0.2) %>%
filter(number > 0) %>%
mutate(id = word_pair)
# Words in second colunm
## That start with he
second_word_he <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
second_word_she <- nodes %>%
filter(x == 2) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 2)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# Words in third colunm
## That start with he
third_word_he <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[1]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
## That start with she
third_word_she <- nodes %>%
filter(x == 3) %>%
select(-n) %>%
left_join(
trigrams %>%
filter(str_nth_word(trigram, 1) == start_words[2]) %>%
mutate(word = str_nth_word(trigram, 3)) %>%
count(word),
by = "word"
) %>%
replace_na(list(n = 0))
# egdes between second and third column that starts with he
egde2_he <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[1], " "))),
second_word_he, third_word_he, n = 50) %>%
mutate(y = y + 0.05,
from = start_words[1],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# egdes between second and third column that starts with she
egde2_she <- egde_lines(filter(trigrams,
str_detect(trigram, paste0("^", start_words[2], " "))),
second_word_she, third_word_she, n = 50) %>%
mutate(y = y - 0.05,
from = start_words[2],
id = str_c(from, word_pair, sep = " ")) %>%
filter(number > 0)
# All edges
edges <- bind_rows(egde1, egde2_he, egde2_she)
p <- nodes %>%
ggplot(aes(x, y, label = word, size = n)) +
geom_text(hjust = 0, color = "#DDDDDD") +
theme_void() +
geom_line(data = edges,
aes(x, y, group = id, color = from, alpha = sqrt(number)),
inherit.aes = FALSE) +
theme(plot.background = element_rect(fill = "#666666", colour = 'black'),
text = element_text(color = "#EEEEEE", size = 15)) +
guides(alpha = "none", color = "none", size = "none") +
xlim(c(0.9, 3.2)) +
scale_color_manual(values = c("#8524A5", "#F79341")) +
labs(title = " Vizualizing trigrams in Sherlock Holmes") +
scale_size(range = c(3, 8))
p
library(details)
sessioninfo::session_info() %>%
details::details(summary = 'session information')
# set-up url for scraping
march20_archive = "https://visualisingideas.edublogs.org/2020/03/"
# Read the HTML code from the website
march_posts <- read_html(march20_archive)
library(tidyverse)
library(rvest)
# function to remove html tags
cleanFun = function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
# set-up url for scraping
march20_archive = "https://visualisingideas.edublogs.org/2020/03/"
# Read the HTML code from the website
march_posts <- read_html(march20_archive)
## install packages
install.packages(c("tidyverse","tidytext","rtweet"), dep = TRUE)
library(tidyverse)
library(tidytext)
library(rtweet)
# include API keys
source("keys.R")
install.packages(c("tidyverse", "tidytext", "rtweet"), dep = TRUE)
## search for tweets
rl_tweets <- search_tweets(q = "#remotelearning", n = 18000, include_rts = FALSE, `-filter` = "replies", lang = "en")
## install packages
# install.packages(c("tidyverse","tidytext","rtweet"), dep = TRUE)
library(tidyverse)
library(tidytext)
library(rtweet)
# include API keys
source("keys.R")
## search for tweets
rl_tweets <- search_tweets(q = "#remotelearning", n = 18000, include_rts = FALSE, `-filter` = "replies", lang = "en")
rl_tweets %>%
sample_n(5) %>%
select(created_at, screen_name, text, favorite_count, retweet_count)
write_as_csv(rl_tweets, "tweets-remotelearning.csv")
ts_plot(tweets, "hours") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with #COVID hashtag",
subtitle = paste0(format(min(tweets$created_at), "%d %B %Y"), " to ", format(max(tweets$created_at),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
ts_plot(rl_tweets, "hours") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with #remotelearning hashtag",
subtitle = paste0(format(min(rl_tweets$created_at), "%d %B %Y"), " to ", format(max(rl_tweets$created_at),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
rl_tweets %>%
arrange(-retweet_count) %>%
slice(1) %>%
select(created_at, screen_name, text, retweet_count)
rl_tweets %>%
count(screen_name, sort = TRUE) %>%
top_n(10) %>%
mutate(screen_name = paste0("@", screen_name))
rl_tweets %>%
unnest_tokens(hashtag, text, "tweets", to_lower = FALSE) %>%
filter(str_detect(hashtag, "^#"),
hashtag != "#ClimateEmergency") %>%
count(hashtag, sort = TRUE) %>%
top_n(10)
rl_tweets %>%
arrange(-favorite_count) %>%
top_n(5, favorite_count) %>%
select(created_at, screen_name, text, favorite_count)
# install.packages("devtools")
devtools::install_github("hadley/emo")
library(emo)
rl_tweets %>%
mutate(emoji = ji_extract_all(text)) %>%
unnest(cols = c(emoji)) %>%
count(emoji, sort = TRUE) %>%
top_n(10)
install.packages("devtools")
devtools::install_github("hadley/emo")
library(emo)
install.packages("devtools")
rl_tweets %>%
mutate(emoji = ji_extract_all(text)) %>%
unnest(cols = c(emoji)) %>%
count(emoji, sort = TRUE) %>%
top_n(10)
words <- rl_tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
words <- rl_tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "rl_tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
words <- rl_tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
# Then we use the wordcloud package to create a visualisation of the word frequencies.
library(wordcloud)
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors = "#F29545"))
words <- rl_tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
# Then we use the wordcloud package to create a visualisation of the word frequencies.
library(wordcloud)
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors = "#F29545"))
View(rl_tweets)
setwd("~/Documents/GitHub/WORKING PROJECTS/edu-disruption")
library(DT)
rl_tweets %>%
sample_n(5) %>%
select(created_at, screen_name, text, favorite_count, retweet_count)
datatable(rl_tweets)
datatable(rl_tweets) %>%
sample_n(5) %>%
select(created_at, screen_name, text, favorite_count, retweet_count)
